{
 "cells": [
  {
   "cell_type": "code",
   "id": "d938793d-003f-475c-882b-f9604d0e1059",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:14.165317Z",
     "start_time": "2025-02-22T19:43:11.525935Z"
    }
   },
   "source": [
    "from benchmark import SmolEvalWrapper, run_benchmarks\n",
    "from think_model import ThinkModelConfig, ThinkTransformer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7b95514f-ec9e-48c4-92a6-f94fb6c7c481",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:14.170129Z",
     "start_time": "2025-02-22T19:43:14.168530Z"
    }
   },
   "source": "device = torch.device(\"cuda:0\")",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "f1f3fe5a-b6c2-416d-a924-84ce751a11e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:14.361894Z",
     "start_time": "2025-02-22T19:43:14.214994Z"
    }
   },
   "source": [
    "hf_checkpoint = \"HuggingFaceTB/SmolLM-360M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(hf_checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:14.609089Z",
     "start_time": "2025-02-22T19:43:14.366995Z"
    }
   },
   "cell_type": "code",
   "source": "!ls think_fineweb-edu_chkpts_exp11",
   "id": "c5bf19836088c794",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.checkpoint.2025-02-21--13-21-57.pt\r\n",
      "model.checkpoint.2025-02-22--01-09-25.pt\r\n",
      "model.checkpoint.2025-02-22--12-57-09.pt\r\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "83601325-53fd-4a9e-b9c0-1d0b97fae0fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:15.541989Z",
     "start_time": "2025-02-22T19:43:14.616264Z"
    }
   },
   "source": [
    "checkpoint_path=\"think_fineweb-edu_chkpts_exp11/model.checkpoint.2025-02-22--12-57-09.pt\"\n",
    "state_dict = torch.load(checkpoint_path, weights_only=True)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "bfa89716-b162-4e35-a929-f8ca7bf048d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:20.038797Z",
     "start_time": "2025-02-22T19:43:16.441470Z"
    }
   },
   "source": [
    "model_config = ThinkModelConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    #\n",
    "    # Generate model\n",
    "    d_model=960,\n",
    "    d_head=64,\n",
    "    d_mlp_proj=2560,\n",
    "    n_generate_layers=12,\n",
    "    n_kv_heads=5,\n",
    "    n_attn_heads=15,\n",
    "    n_cross_attn_heads=15,\n",
    "    generate_initializer_range=0.002,\n",
    "    #\n",
    "    # Think model\n",
    "    think_d_model=960,\n",
    "    think_d_head=64,\n",
    "    think_d_mlp_proj=2560,\n",
    "    n_think_kv_heads=5,\n",
    "    n_think_attn_heads=15,\n",
    "    n_think_layers=32,\n",
    "    think_initializer_range=0.02,\n",
    "    #\n",
    "    # Others\n",
    "    encode_interval=8,\n",
    "    rms_norm_eps=1e-5,\n",
    "    rope_theta=100000.0,\n",
    "    padding_idx=tokenizer.pad_token_id\n",
    ")\n",
    "model = ThinkTransformer(model_config)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "cfe07ed6-4913-47eb-835c-87d5e1442a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:21.126981Z",
     "start_time": "2025-02-22T19:43:20.920585Z"
    }
   },
   "source": "model.load_state_dict(state_dict)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9cafe5bd-49e8-467f-b36a-ad38f0fe79ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:22.251142Z",
     "start_time": "2025-02-22T19:43:22.001037Z"
    }
   },
   "source": [
    "model.to(device)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThinkTransformer(\n",
       "  (think_network): ThinkNetwork(\n",
       "    (embed_tokens): Embedding(49152, 960)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x EncoderLayer(\n",
       "        (self_attn): GroupedQueryAttention(\n",
       "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "        )\n",
       "        (mlp): GatedMlp(\n",
       "          (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (input_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): Rotary()\n",
       "  )\n",
       "  (generate_network): GenerateNetwork(\n",
       "    (embed_tokens): Embedding(49152, 960)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x CrossAttnDecoderLayer(\n",
       "        (self_attn): GroupedQueryAttention(\n",
       "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "        )\n",
       "        (cross_attn): GroupedQueryAttention(\n",
       "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (k_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (v_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "        )\n",
       "        (mlp): GatedMlp(\n",
       "          (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (self_attn_input_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn_input_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): Linear(in_features=960, out_features=49152, bias=False)\n",
       "    (rotary_emb): Rotary()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "22d017fb-30df-4407-b3b2-48a8dbc13f74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:23.124112Z",
     "start_time": "2025-02-22T19:43:23.120432Z"
    }
   },
   "source": [
    "model.eval()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThinkTransformer(\n",
       "  (think_network): ThinkNetwork(\n",
       "    (embed_tokens): Embedding(49152, 960)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x EncoderLayer(\n",
       "        (self_attn): GroupedQueryAttention(\n",
       "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "        )\n",
       "        (mlp): GatedMlp(\n",
       "          (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (input_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "    (rotary_emb): Rotary()\n",
       "  )\n",
       "  (generate_network): GenerateNetwork(\n",
       "    (embed_tokens): Embedding(49152, 960)\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x CrossAttnDecoderLayer(\n",
       "        (self_attn): GroupedQueryAttention(\n",
       "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (k_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (v_proj): Linear(in_features=960, out_features=320, bias=False)\n",
       "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "        )\n",
       "        (cross_attn): GroupedQueryAttention(\n",
       "          (q_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (k_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (v_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "          (o_proj): Linear(in_features=960, out_features=960, bias=False)\n",
       "        )\n",
       "        (mlp): GatedMlp(\n",
       "          (up_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (gate_proj): Linear(in_features=960, out_features=2560, bias=False)\n",
       "          (down_proj): Linear(in_features=2560, out_features=960, bias=False)\n",
       "          (silu): SiLU()\n",
       "        )\n",
       "        (self_attn_input_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "        (cross_attn_input_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "        (post_attention_layernorm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm((960,), eps=1e-05, elementwise_affine=True)\n",
       "    (lm_head): Linear(in_features=960, out_features=49152, bias=False)\n",
       "    (rotary_emb): Rotary()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "cc3737f5-f141-4591-bb4a-27b0dd8658a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:23.992376Z",
     "start_time": "2025-02-22T19:43:23.990829Z"
    }
   },
   "source": [
    "eval_wrapper = SmolEvalWrapper(model, tokenizer, device, batch_size=8)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e82034df-3866-40ef-a051-47ec212c1ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:43:24.867828Z",
     "start_time": "2025-02-22T19:43:24.866240Z"
    }
   },
   "source": "task = \"hellaswag\"",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "6e84d65c-be4c-4315-8e61-d036e0ec536e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T19:59:58.465346Z",
     "start_time": "2025-02-22T19:43:26.772216Z"
    }
   },
   "source": [
    "results = run_benchmarks(eval_wrapper, [task], limit=100)\n",
    "metric_keys = results['results'][task].keys() - ['alias']\n",
    "metric_values = {metric: results['results'][task][metric] for metric in metric_keys}\n",
    "metric_values"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22:11:43:31,031 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-22:11:43:31,032 INFO     [__init__.py:459] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.\n",
      "2025-02-22:11:43:33,509 INFO     [task.py:420] Building contexts for hellaswag on rank 0...\n",
      "100%|██████████| 100/100 [00:00<00:00, 8314.94it/s]\n",
      "2025-02-22:11:43:33,529 INFO     [evaluator.py:513] Running loglikelihood requests\n",
      "100%|██████████| 400/400 [16:24<00:00,  2.46s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc,none': 0.39,\n",
       " 'acc_norm,none': 0.44,\n",
       " 'acc_norm_stderr,none': 0.04988876515698589,\n",
       " 'acc_stderr,none': 0.04902071300001975}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "817e60fc-1b60-43ce-9c60-600d35aa33aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T20:00:09.625595Z",
     "start_time": "2025-02-22T19:59:59.345770Z"
    }
   },
   "source": [
    "input_text = \"\"\"\n",
    "Ideas for the weekend\n",
    "- Hike in the redwood trees\n",
    "- Picnic near the lake\n",
    "-\n",
    "\"\"\".strip()\n",
    "\n",
    "input_ids = tokenizer([input_text], return_tensors=\"pt\")['input_ids'].to(\"cuda\")\n",
    "idx = model.generate(input_ids, temperature=0.25, top_k=50, max_new_tokens=64, think_r=128)\n",
    "print(tokenizer.batch_decode(idx)[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideas for the weekend\n",
      "- Hike in the redwood trees\n",
      "- Picnic near the lake\n",
      "- The 1960s: This is a time when the hippie movement was gaining momentum, which created a wave of hippie artists who were trying to create a new kind of art. Artists such as Dadaist, Pop, and Minimalism were among the first to take up the movement. But the\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-22T20:00:09.629992Z",
     "start_time": "2025-02-22T20:00:09.628754Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f5c9f4d409dcbc3a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
