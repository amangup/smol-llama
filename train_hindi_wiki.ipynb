{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T06:13:14.675807Z",
     "start_time": "2024-12-16T06:13:13.745871Z"
    }
   },
   "source": [
    "from model import ModelConfig, LlamaModel\n",
    "from train import TrainerConfig, FileDataLoader, Trainer\n",
    "\n",
    "from transformers import AutoTokenizer"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T06:13:14.680027Z",
     "start_time": "2024-12-16T06:13:14.678406Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer_id = \"HuggingFaceTB/SmolLM2-135M\"",
   "id": "2f28fa23c987e72b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T06:13:14.942699Z",
     "start_time": "2024-12-16T06:13:14.724783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ],
   "id": "9bb4e51aa142abee",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T06:13:14.949885Z",
     "start_time": "2024-12-16T06:13:14.948274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_config = ModelConfig(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    d_model=576,\n",
    "    d_head=64,\n",
    "    d_mlp_proj=1536,\n",
    "    n_layers=30,\n",
    "    n_kv_heads=3,\n",
    "    n_attn_heads=9,\n",
    "    rms_norm_eps=1e-5,\n",
    "    initializer_range=0.041666666666666664,\n",
    "    rope_theta=100000.0,\n",
    "    padding_idx=tokenizer.pad_token_id\n",
    ")"
   ],
   "id": "cde027092af8291e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_config = TrainerConfig(\n",
    "    per_device_train_batch_size=8,\n",
    "    max_seq_len=2048,\n",
    "    num_epochs=1,\n",
    "    eval_interval_steps=100,\n",
    "    learning_rate=1e-3,\n",
    "    tokens_folder=\"wiki_hindi_tok\",\n",
    "    max_steps=2000,\n",
    "    log_dir=\"runs/shakespeare\"\n",
    ")"
   ],
   "id": "c0897594b27eb59f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = LlamaModel(model_config)\n",
    "dataloader = FileDataLoader(train_config, tokenizer)\n",
    "trainer = Trainer(train_config, model)"
   ],
   "id": "6504e357e2012d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "trainer.train(dataloader)",
   "id": "c853027a7a843745"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T06:27:54.880836Z",
     "start_time": "2024-12-16T06:27:52.251011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_ids = tokenizer([\"आज की चर्चा\"], return_tensors=\"pt\")['input_ids'].to(trainer.device)\n",
    "idx = model.generate(input_ids, temperature=0.25, top_k=50, max_new_tokens=256)\n",
    "print(tokenizer.batch_decode(idx)[0])"
   ],
   "id": "8b5596eda083de0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "आज की चर्चा मिलता है। इसके प्रमुख प्रभावित होने के लिए प्रति प्राप्त होते हैं। इसका प्राचीन प्रकाशित होता है। इसके अतिरिक्त प्रसारण में ही प्रतिभाग्य प्राप्त होता है। इसके प्रभावित हैं। इस प्रकार के अनुसार अपने प्रतिपत्ति में ही है। विश्वास म\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "bc3bcc343073d67a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
